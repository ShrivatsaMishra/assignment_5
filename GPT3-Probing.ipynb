{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c697ed",
   "metadata": {},
   "source": [
    "# Prompt Engineering and Probing with GPT3\n",
    "\n",
    "With GPT3, we can do a variety of tasks without the need of training a model. All we need to do is convert the task into an text generation task that follows a set of instructions called *prompts*. As an example, the task of sentiment classification can be designed as:\n",
    "\n",
    "```\n",
    "Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: I loved the new Batman movie!\n",
    "Sentiment:\n",
    "```\n",
    "\n",
    "The GPT3 model then completes the text above with the response **Positive**. The above prompt is an example of zero-shot learning, meaning, we are not providing any signal/direction that can guide the decision and merely rely on GPT's pretraining objective:\n",
    "\n",
    "```\n",
    "Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: I really liked the Spiderman movie!\n",
    "Sentiment: Positive\n",
    "\n",
    "Tweet: I loved the new Batman movie!\n",
    "Sentiment:\n",
    "```\n",
    "\n",
    "Now this is an example of 1-shot learning, i.e., you are providing an labeled example of how the output should look and then ask GPT to complete the next example. When you use more than 1 labeled example, it is known as few-shot learning.  Generally, if you provide more examples in the prompt, it will make better predictions.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "\n",
    "In this assignment, we will first need to register for an account at: https://platform.openai.com/ As a free trial, you will get $18 credits to make api calls to the GPT server. Once registered, you should go through the docs here: https://platform.openai.com/docs/guides/completion/prompt-design to get more info on the capabilities of the model. \n",
    "\n",
    "You can either do this homework using the free to use playground/chat interface of openai using the following links:\n",
    "\n",
    "- [https://platform.openai.com/playground](https://platform.openai.com/playground)\n",
    "- [https://chat.openai.com](https://chat.openai.com)\n",
    "\n",
    "But if you want to use the API to make automatic calls to open ai, we will need to follow the steps below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "806993a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/hylaa-0+untagged.602.ga774f8e-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.3.5)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f88e0fce-4d55-4fd3-9ea3-eeadefb11dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## Find the API key by clicking on your profile in the openai page. Add the key to the environment as following:\n",
    "## Make sure to delete this cell afterwords\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '...'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf90729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc7bd8-b70f-49d4-90ab-79b9eb63121b",
   "metadata": {},
   "source": [
    "## Using text completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce117de",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\\n\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment:\",\n",
    "  temperature=0,\n",
    "  max_tokens=60,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1900d9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-8QOUEoPOrHPVnDRZcKh12O4RcUiJv', choices=[CompletionChoice(finish_reason='stop', index=0, logprobs=None, text=' Positive')], created=1701301346, model='text-davinci-002', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=31, total_tokens=32), warning='This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6444ebbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Positive'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6245ed-ddba-469e-a5d4-85ce8a9e6513",
   "metadata": {},
   "source": [
    "## Using chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48670dc9-e5d1-4160-bebc-8bf7f9b27454",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a Sentiment Classifier.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Decide whether a Tweet's sentiment is positive, neutral, or negative.\\n\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment:\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85e3c05-e7de-4422-bc1c-eebcc802d3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8QOUKIdzvO8hPjrR86BfDJfogvxla', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Positive', role='assistant', function_call=None, tool_calls=None))], created=1701301352, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=46, total_tokens=47))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23316601-6833-49ea-a487-5ce7433be9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0af83",
   "metadata": {},
   "source": [
    "If you see ' Positive' as response in the above cell, you have successfully set-up gpt3 in your system.\n",
    "\n",
    "Now, the task for the assignment is really just do something cool. For example, you could probe how well GPT3 performs on the tasks in the previous HWs. Or, you could do something like question-answering or summarization, that were not covered in the assignments. The choice is yours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12524b5b-7d1a-4cba-89a0-724b4f3f4008",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcba73ee-f806-41dc-8863-123e55baecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a text summarizer\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8766a25c-1bda-4c02-8d49-0d5162542c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This paper discusses the recent advancements in Virtual Reality (VR) technology, focusing on the second wave of VR that has occurred in the past three years. It highlights the introduction of new displays and input devices, as well as the development of new technologies and concepts for handling existing problems. The development of VR hardware and software is predominantly led by enthusiasts, rather than the established scientific community. The paper also explores various devices that are gaining importance in the field of VR, such as haptics devices, controllers, treadmills, and tracking technologies. It emphasizes that these technologies are now precise and robust enough for professional and scientific use. The paper further addresses common issues with VR technologies, including motion-to-photon latency, barrel distortion, and low-persistence displays, and discusses the approaches to solving these problems. It concludes with an analysis of the available solutions and provides a taxonomy categorizing the current developments in VR. Overall, the paper provides a comprehensive overview of the recent developments in VR technology and considers the future advancements in both hardware and software.\n"
     ]
    }
   ],
   "source": [
    "abstract =\"In the past three years, the so-called second wave of Virtual Reality (VR) has brought us a vast amount of new displays and input devices. Not only new hardware has entered the consumer market providing affordable pricing models but also completely new technologies are being designed and developed. Additionally new concepts for handling existing problems on the hardware and software side of the VR technology are constantly being introduced. This software and hardware development is mainly lead by enthusiasts interested in the domain of VR opposed to the established scientific community, which already partially makes use of the newly available technology. Besides Head-Mounted Displays (HMDs), either cable-based or mobile, other devices like haptics devices, controllers, vests, omnidirectional treadmills, tracking technologies, as well as optical scanners for gesture-based interaction are gaining importance in the field of commodity VR. Most of these technologies are already precise and robust enough to be used for professional operation and scientific experiments. The topics discussed are the common issues with the new technologies including the approaches to solve them as for example motion-to-photon latency, barrel distortion, and low-persistence displays. Additionally an in-depth analysis of the available solutions expected to hit the market is provided. A taxonomy categorising the current developments with the chosen implementation approaches will be given. The paper analyses the state of technological advancements in the field and provides an extensive overview on the current development considering the upcoming devices and the advancements from the software side.\"\n",
    "summary = summarize(abstract)\n",
    "print(summary.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2504cd6-d610-40f0-b892-e6015dee1de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a text summarizer\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize the following: {text}\"}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a81d9d1c-f2bc-4a4a-9f2e-74bb0f30fcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The past three years have seen significant advancements in Virtual Reality (VR), with new hardware and technologies being developed. Enthusiasts are leading the way in this domain, with new concepts and solutions constantly being introduced. In addition to Head-Mounted Displays (HMDs), other devices like haptics devices, controllers, and tracking technologies are gaining importance. These technologies are already precise enough for professional and scientific use. Common issues with these technologies, such as motion-to-photon latency and barrel distortion, are being addressed, and solutions are expected to hit the market soon. This paper provides a comprehensive overview of the current advancements in VR technology, including upcoming devices and software advancements.\n"
     ]
    }
   ],
   "source": [
    "abstract =\"In the past three years, the so-called second wave of Virtual Reality (VR) has brought us a vast amount of new displays and input devices. Not only new hardware has entered the consumer market providing affordable pricing models but also completely new technologies are being designed and developed. Additionally new concepts for handling existing problems on the hardware and software side of the VR technology are constantly being introduced. This software and hardware development is mainly lead by enthusiasts interested in the domain of VR opposed to the established scientific community, which already partially makes use of the newly available technology. Besides Head-Mounted Displays (HMDs), either cable-based or mobile, other devices like haptics devices, controllers, vests, omnidirectional treadmills, tracking technologies, as well as optical scanners for gesture-based interaction are gaining importance in the field of commodity VR. Most of these technologies are already precise and robust enough to be used for professional operation and scientific experiments. The topics discussed are the common issues with the new technologies including the approaches to solve them as for example motion-to-photon latency, barrel distortion, and low-persistence displays. Additionally an in-depth analysis of the available solutions expected to hit the market is provided. A taxonomy categorising the current developments with the chosen implementation approaches will be given. The paper analyses the state of technological advancements in the field and provides an extensive overview on the current development considering the upcoming devices and the advancements from the software side.\"\n",
    "summary = summarize(abstract)\n",
    "print(summary.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa0911-2c0c-4175-a0d8-9976539c6b78",
   "metadata": {},
   "source": [
    "### POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16777389-cfb0-4f93-b5c5-9f07a4adc90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(text): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a pos tagger\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8336efb-f4c3-49b6-945d-333a94ea69c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shoot/VB all/DT the/DT blue/JJ jays/NNS you/PRP want/VBP ,/, if/IN you/PRP can/MD hit/VB em/PRP ,/, but/CC remember/VB that/IN it/PRP ’/VBZ s/VBZ a/DT sin/NN to/TO kill/VB a/DT mockingbird/NN ./.\n"
     ]
    }
   ],
   "source": [
    "text = \"Shoot all the blue jays you want, if you can hit em, but remember that it’s a sin to kill a mockingbird.\"\n",
    "tagged = pos(text)\n",
    "print(tagged.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70a49526-1d17-4d49-a87c-711f860e2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(text): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a pos tagger given the tags \\nADJ: adjective\\nADP: adposition\\nADV: adverb\\nAUX: auxiliary\\nCCONJ: coordinating conjunction\\nDET: determiner\\nINTJ: interjection\\nNOUN: noun\\nNUM: numeral\\nPART: particle\\nPRON: pronoun\\nPROPN: proper noun\\nPUNCT: punctuation\\nSCONJ: subordinating conjunction\\nSYM: symbol\\nVERB: verb\\nX: other\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf41367b-ddef-4fcd-9aea-7cf5b41098d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shoot/VERB all/DET the/DET blue/ADJ jays/NOUN you/PRON want/VERB ,/PUNCT if/SCONJ you/PRON can/VERB hit/VERB em/PART ,/PUNCT but/CCONJ remember/VERB that/ADP it/PRON ’s/AUX a/DET sin/NOUN to/ADP kill/VERB a/DET mockingbird/NOUN ./PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = \"Shoot all the blue jays you want, if you can hit em, but remember that it’s a sin to kill a mockingbird.\"\n",
    "tagged = pos(text)\n",
    "print(tagged.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fabd68-7c97-4d34-bb70-8dcadb490f89",
   "metadata": {},
   "source": [
    "### Irony Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e916d41d-c4d1-4838-bdcb-4e0bb09485c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def irony(text): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Is there irony present in the text\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34b2efa1-8a35-4da2-9581-12d0a8f1e2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there is irony present in the text. The irony lies in the fact that while it is acceptable to shoot blue jays, it is considered a sin to kill a mockingbird. The mockingbird is used as a metaphor for innocence and harmlessness, as it is a bird that only sings and does not harm anyone. By stating the sinfulness of killing a mockingbird, the speaker is implying that it is wrong to harm something or someone that is innocent and harmless.\n"
     ]
    }
   ],
   "source": [
    "text = \"Shoot all the blue jays you want, if you can hit em, but remember that it’s a sin to kill a mockingbird.\"\n",
    "entities = irony(text)\n",
    "print(entities.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dee2f9f3-4042-45cb-8bff-489a24ed3e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no irony present in this text.\n"
     ]
    }
   ],
   "source": [
    "text = \"To Kill a Mockingbird is a novel by the American author Harper Lee. It was published in 1960 and was instantly successful. In the United States, it is widely read in high schools and middle schools. \"\n",
    "result = irony(text)\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db4d020f-430d-4c72-a7dc-35ff2500f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def irony(text): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an irony detection system\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Is there irony present in: {text}\"}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f782093-525d-41d7-8423-ad4c26ec8076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there is irony present in the statement. The irony lies in the juxtaposition of shooting blue jays, which is allowed and seemingly encouraged, while highlighting the sinfulness of killing a mockingbird. Mockingbirds are innocent creatures that only bring joy through their songs, thus the statement is ironic because it suggests a contradiction between the treatment of different species of birds.\n"
     ]
    }
   ],
   "source": [
    "text = \"Shoot all the blue jays you want, if you can hit em, but remember that it’s a sin to kill a mockingbird.\"\n",
    "entities = irony(text)\n",
    "print(entities.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dbda3e6-d540-4113-be08-a7487d1983fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, there is no irony present in the provided statement. It simply states information about the novel \"To Kill a Mockingbird\" and its success.\n"
     ]
    }
   ],
   "source": [
    "text = \"To Kill a Mockingbird is a novel by the American author Harper Lee. It was published in 1960 and was instantly successful. In the United States, it is widely read in high schools and middle schools. \"\n",
    "result = irony(text)\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd80e8-7245-4a01-ba89-6dc7f0bd541f",
   "metadata": {},
   "source": [
    "### Natural Language Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8749b5fa-303c-4ae2-9b7b-6ff971b5cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nli(s1, s2): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Premise: {s1}\\n Hypothesis 2: {s2}\"}\n",
    "      ]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Given two sentences: a premise and a hypothesis, you need to classify the relation between them. We have three classes to describe this relationship.\\nEntailment: the hypothesis follows from the fact that the premise is true\\nContradiction: the hypothesis contradicts the fact that the premise is true\\nNeutral: There is no relationship between premise and hypothesis\"},\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eed2be33-d758-4097-8c3e-1f6d64c531e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is important to note that hypothesis 2 cannot be derived from the given premise. The premise only mentions a man inspecting the uniform of a figure in some East Asian country. There is no information provided about the man's state of consciousness or whether he is sleeping. Therefore, hypothesis 2 is not supported by the given premise.\n",
      "\n",
      "The hypothesis provided does not directly relate to the given premise, which focuses on a black race car starting up in front of a crowd of people. It introduces a different scenario involving a man driving down a lonely road.\n",
      "\n",
      "Your hypothesis is not specific enough to be proven or disproven based on the given premise. The premise states that a soccer game with multiple males playing is taking place, but it does not provide enough information to determine if the sport being played is solely soccer or if there are other sports involved as well. Additionally, the premise does not explicitly state the gender of all the players, only mentioning that there are multiple males playing. Therefore, it is not possible to validate or invalidate the hypothesis solely based on the given premise.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "premises=[\"A man inspects the uniform of a figure in some East Asian country.\", \"A black race car starts up in front of a crowd of people.\", \"A soccer game with multiple males playing.\"]\n",
    "hypothesi=[\"The man is sleeping\", \"A man is driving down a lonely road.\", \"Some men are playing a sport.\"]\n",
    "\n",
    "for i in range(len(premises)):\n",
    "    inference = nli(premises[i], hypothesi[i])\n",
    "    print(inference.choices[0].message.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d574b9ec-0b1a-44f9-b86b-366dac2f0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nli(s1, s2): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Given two sentences: a premise and a hypothesis, you need to classify the relation between them and provide an explanation. We have three classes to describe this relationship.\\nEntailment: the hypothesis follows from the fact that the premise is true\\nContradiction: the hypothesis contradicts the fact that the premise is true\\nNeutral: There is no relationship between premise and hypothesis\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Premise: {s1}\\n Hypothesis 2: {s2}\"}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bf5a0f6-9409-4e14-9b4a-952a4b105e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Neutral\n",
      "\n",
      "Explanation: The two sentences do not have a clear relationship. The premise talks about a man inspecting a uniform, while the hypothesis states that the man is sleeping. There is no inherent contradiction or entailment between the two statements. They can coexist without affecting each other.\n",
      "\n",
      "Classification: Neutral\n",
      "\n",
      "Explanation: The premise and the hypothesis do not have any clear relationship. The premise mentions a race car starting up in front of a crowd, while the hypothesis talks about a man driving down a lonely road. These two sentences describe different scenarios and do not support or contradict each other.\n",
      "\n",
      "Relation: Entailment\n",
      "\n",
      "Explanation: The premise states that there is a soccer game with multiple males playing. The hypothesis states that some men are playing a sport. Since soccer is a sport and the premise explicitly mentions males playing it, the hypothesis follows from the fact that the premise is true.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "premises=[\"A man inspects the uniform of a figure in some East Asian country.\", \"A black race car starts up in front of a crowd of people.\", \"A soccer game with multiple males playing.\"]\n",
    "hypothesi=[\"The man is sleeping\", \"A man is driving down a lonely road.\", \"Some men are playing a sport.\"]\n",
    "\n",
    "for i in range(len(premises)):\n",
    "    inference = nli(premises[i], hypothesi[i])\n",
    "    print(inference.choices[0].message.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "355d5163-51cd-415a-9494-23a39998cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nli(s1, s2): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Given two sentences: a premise and a hypothesis, you need to classify the relation between them. We have three classes to describe this relationship: Entailment, Contradiction, Neutral\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Premise: {s1}\\n Hypothesis 2: {s2}\"}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d21cd4d2-8c5e-445b-880b-bfc08ffa5578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contradiction\n",
      "\n",
      "Relation: Neutral\n",
      "\n",
      "Entailment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "premises=[\"A man inspects the uniform of a figure in some East Asian country.\", \"A black race car starts up in front of a crowd of people.\", \"A soccer game with multiple males playing.\"]\n",
    "hypothesi=[\"The man is sleeping\", \"A man is driving down a lonely road.\", \"Some men are playing a sport.\"]\n",
    "\n",
    "for i in range(len(premises)):\n",
    "    inference = nli(premises[i], hypothesi[i])\n",
    "    print(inference.choices[0].message.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31660025",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Please submit a written report of what task you tried probing, how well did GPT3 do for that task and what were your key takeaways in this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66f992-cecb-41aa-8e95-d6e6f625c86c",
   "metadata": {},
   "source": [
    "I have conducted an in-depth exploration of the ChatGPT API and experimented with various applications. In an attempt to fulfill assignments, I utilized ChatGPT for diverse tasks, achieving varying degrees of success.\n",
    "\n",
    "* #### Summarisation\n",
    "  The model exhibited notable proficiency in summarizing text. Specifically, I endeavored to summarize the abstract of a paper by employing the model, resulting in a satisfactory outcome. My experimentation involved employing two distinct prompts, each yielding commendable results. One prompt solely utilized the system's message, while the other incorporated the task description within the message.\n",
    "  \n",
    "* #### POS Tagging\n",
    "  Initially, I refrained from providing specific tags for POS tagging. This approach yielded an unconventional yet comprehensible form of POS tags. Subsequently, when supplied with explicit tags, the model excelled, generating accurate POS tags for all the words in the given context.\n",
    "  \n",
    "* #### Irony detection\n",
    "  The model demonstrated proficient performance in detecting irony within sentences, successfully discerning instances of both irony and its absence. Similar to the summarization task, I provided the task in both the system message and the user message, resulting in effective irony detection.\n",
    "  \n",
    "* #### NLI\n",
    "  Unfortunately, the model exhibited limitations in its ability to perform Natural Language Inference (NLI) to a satisfactory extent. While experimenting with various prompts and system messages, I identified three approaches that appeared most promising. Due to the presence of multiple tags, additional test cases were essential. However, it is noteworthy that OpenAI imposed a constraint of three prompts per minute. Ultimately, I achieved a moderately acceptable outcome by shortening the system message and omitting the explanation of the tags.\n",
    "\n",
    "\n",
    "In summary, my exploration of the ChatGPT API revealed its effectiveness in tasks such as text summarization, POS tagging, and irony detection. The model successfully condensed information, accurately tagged parts of speech, and discerned irony in sentences. Challenges emerged in Natural Language Inference (NLI), where the model displayed limitations, though experimentation identified more effective approaches. While the ChatGPT API demonstrated commendable capabilities, ongoing refinement may be necessary, particularly in nuanced applications like NLI, to further enhance its effectiveness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
