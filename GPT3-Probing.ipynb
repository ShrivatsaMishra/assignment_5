{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c697ed",
   "metadata": {},
   "source": [
    "# Prompt Engineering and Probing with GPT3\n",
    "\n",
    "With GPT3, we can do a variety of tasks without the need of training a model. All we need to do is convert the task into an text generation task that follows a set of instructions called *prompts*. As an example, the task of sentiment classification can be designed as:\n",
    "\n",
    "```\n",
    "Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: I loved the new Batman movie!\n",
    "Sentiment:\n",
    "```\n",
    "\n",
    "The GPT3 model then completes the text above with the response **Positive**. The above prompt is an example of zero-shot learning, meaning, we are not providing any signal/direction that can guide the decision and merely rely on GPT's pretraining objective:\n",
    "\n",
    "```\n",
    "Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: I really liked the Spiderman movie!\n",
    "Sentiment: Positive\n",
    "\n",
    "Tweet: I loved the new Batman movie!\n",
    "Sentiment:\n",
    "```\n",
    "\n",
    "Now this is an example of 1-shot learning, i.e., you are providing an labeled example of how the output should look and then ask GPT to complete the next example. When you use more than 1 labeled example, it is known as few-shot learning.  Generally, if you provide more examples in the prompt, it will make better predictions.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "\n",
    "In this assignment, we will first need to register for an account at: https://platform.openai.com/ As a free trial, you will get $18 credits to make api calls to the GPT server. Once registered, you should go through the docs here: https://platform.openai.com/docs/guides/completion/prompt-design to get more info on the capabilities of the model. \n",
    "\n",
    "You can either do this homework using the free to use playground/chat interface of openai using the following links:\n",
    "\n",
    "- [https://platform.openai.com/playground](https://platform.openai.com/playground)\n",
    "- [https://chat.openai.com](https://chat.openai.com)\n",
    "\n",
    "But if you want to use the API to make automatic calls to open ai, we will need to follow the steps below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "806993a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/hylaa-0+untagged.602.ga774f8e-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.3.5)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f88e0fce-4d55-4fd3-9ea3-eeadefb11dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## Find the API key by clicking on your profile in the openai page. Add the key to the environment as following:\n",
    "## Make sure to delete this cell afterwords\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '...'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf90729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc7bd8-b70f-49d4-90ab-79b9eb63121b",
   "metadata": {},
   "source": [
    "## Using text completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce117de",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\\n\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment:\",\n",
    "  temperature=0,\n",
    "  max_tokens=60,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1900d9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(id='cmpl-8Pc4YhyV5ufgaqno1sg1iKyn81YNj', choices=[CompletionChoice(finish_reason='stop', index=0, logprobs=None, text=' Positive')], created=1701115242, model='text-davinci-002', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=31, total_tokens=32), warning='This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6444ebbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Positive'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6245ed-ddba-469e-a5d4-85ce8a9e6513",
   "metadata": {},
   "source": [
    "## Using chat completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48670dc9-e5d1-4160-bebc-8bf7f9b27454",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a Sentiment Classifier.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Decide whether a Tweet's sentiment is positive, neutral, or negative.\\n\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment:\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c85e3c05-e7de-4422-bc1c-eebcc802d3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8Pc4fRJ7VNqfnzKpiLeNuWyQLArwW', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='positive', role='assistant', function_call=None, tool_calls=None))], created=1701115249, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=46, total_tokens=47))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23316601-6833-49ea-a487-5ce7433be9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0af83",
   "metadata": {},
   "source": [
    "If you see ' Positive' as response in the above cell, you have successfully set-up gpt3 in your system.\n",
    "\n",
    "Now, the task for the assignment is really just do something cool. For example, you could probe how well GPT3 performs on the tasks in the previous HWs. Or, you could do something like question-answering or summarization, that were not covered in the assignments. The choice is yours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12524b5b-7d1a-4cba-89a0-724b4f3f4008",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcba73ee-f806-41dc-8863-123e55baecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a text summarizer\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8766a25c-1bda-4c02-8d49-0d5162542c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract =\"In the past three years, the so-called second wave of Virtual Reality (VR) has brought us a vast amount of new displays and input devices. Not only new hardware has entered the consumer market providing affordable pricing models but also completely new technologies are being designed and developed. Additionally new concepts for handling existing problems on the hardware and software side of the VR technology are constantly being introduced. This software and hardware development is mainly lead by enthusiasts interested in the domain of VR opposed to the established scientific community, which already partially makes use of the newly available technology. Besides Head-Mounted Displays (HMDs), either cable-based or mobile, other devices like haptics devices, controllers, vests, omnidirectional treadmills, tracking technologies, as well as optical scanners for gesture-based interaction are gaining importance in the field of commodity VR. Most of these technologies are already precise and robust enough to be used for professional operation and scientific experiments. The topics discussed are the common issues with the new technologies including the approaches to solve them as for example motion-to-photon latency, barrel distortion, and low-persistence displays. Additionally an in-depth analysis of the available solutions expected to hit the market is provided. A taxonomy categorising the current developments with the chosen implementation approaches will be given. The paper analyses the state of technological advancements in the field and provides an extensive overview on the current development considering the upcoming devices and the advancements from the software side.\"\n",
    "summary = summarize(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2504cd6-d610-40f0-b892-e6015dee1de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the past few years, there has been a surge in the development of Virtual Reality (VR) technology. This second wave of VR has brought about new displays and input devices, making the technology more accessible and affordable for consumers. Enthusiasts are leading the way in driving this development, with new hardware and software concepts constantly emerging.\n",
      "\n",
      "Aside from the commonly known Head-Mounted Displays (HMDs), other devices like haptics devices, controllers, vests, omnidirectional treadmills, tracking technologies, and optical scanners are gaining importance in the VR field. Many of these technologies are already precise and robust enough to be used in professional and scientific settings.\n",
      "\n",
      "There are, however, common issues with these new technologies that need to be addressed. These include motion-to-photon latency, barrel distortion, and low-persistence displays. The paper discusses the approaches to solving these problems and provides an in-depth analysis of the upcoming solutions expected to hit the market.\n",
      "\n",
      "The paper also provides a taxonomy that categorizes the current developments and implementation approaches in the field of VR. It offers an extensive overview of the state of technological advancements, considering both the upcoming devices and the advancements in software.\n",
      "\n",
      "Overall, the paper showcases the progress and potential of VR technology, highlighting the advancements made by enthusiasts and the promising future developments in the field.\n"
     ]
    }
   ],
   "source": [
    "# print(summary)\n",
    "print(summary.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa0911-2c0c-4175-a0d8-9976539c6b78",
   "metadata": {},
   "source": [
    "### POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70a49526-1d17-4d49-a87c-711f860e2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(text): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a pos tagger given the tags \\nADJ: adjective\\nADP: adposition\\nADV: adverb\\nAUX: auxiliary\\nCCONJ: coordinating conjunction\\nDET: determiner\\nINTJ: interjection\\nNOUN: noun\\nNUM: numeral\\nPART: particle\\nPRON: pronoun\\nPROPN: proper noun\\nPUNCT: punctuation\\nSCONJ: subordinating conjunction\\nSYM: symbol\\nVERB: verb\\nX: other\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf41367b-ddef-4fcd-9aea-7cf5b41098d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Shoot all the blue jays you want, if you can hit em, but remember that it’s a sin to kill a mockingbird.\"\n",
    "tagged = pos(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e77e9fc-623e-4a44-8d08-3e3ceef4e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shoot/VERB all/DET the/DET blue/ADJ jays/NOUN you/PRON want/VERB, if/SCONJ you/PRON can/VERB hit/VERB em/PRON, but/CCONJ remember/VERB that/SCONJ it/PRON ’s/AUX a/DET sin/NOUN to/PART kill/VERB a/DET mockingbird/NOUN ./PUNCT\n"
     ]
    }
   ],
   "source": [
    "# print(tagged)\n",
    "print(tagged.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fabd68-7c97-4d34-bb70-8dcadb490f89",
   "metadata": {},
   "source": [
    "### Irony Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e916d41d-c4d1-4838-bdcb-4e0bb09485c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def irony(text): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Is there irony present in the text\"},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34b2efa1-8a35-4da2-9581-12d0a8f1e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Shoot all the blue jays you want, if you can hit em, but remember that it’s a sin to kill a mockingbird.\"\n",
    "entities = irony(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76b8e0fc-388d-495a-a62b-5ca3e673cdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, there is irony present in the text. The irony lies in the fact that while it is portrayed as acceptable to shoot blue jays, it is deemed a sin to kill a mockingbird. This statement suggests that there is a moral distinction between the two, even though both species are simply birds. The irony emphasizes the unjust treatment of mockingbirds, which symbolize innocence and harmlessness in Harper Lee's novel \"To Kill a Mockingbird.\"\n"
     ]
    }
   ],
   "source": [
    "# print(entities)\n",
    "print(entities.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dee2f9f3-4042-45cb-8bff-489a24ed3e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given information, there is no apparent irony present in the text. It simply provides factual details about the novel and its publication. Irony refers to a situation where there is a contrast between what is expected and what actually happens.\n"
     ]
    }
   ],
   "source": [
    "text = \"o Kill a Mockingbird is a novel by the American author Harper Lee. It was published in 1960 and was instantly successful. In the United States, it is widely read in high schools and middle schools. \"\n",
    "result = irony(text)\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd80e8-7245-4a01-ba89-6dc7f0bd541f",
   "metadata": {},
   "source": [
    "### Natural Language Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d574b9ec-0b1a-44f9-b86b-366dac2f0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nli(s1, s2): \n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"The task is, give two sentences: a premise and a hypothesis, to classify the relation between them and provide an explanation. We have three classes to describe this relationship.\\nEntailment: the hypothesis follows from the fact that the premise is true\\nContradiction: the hypothesis contradicts the fact that the premise is true\\nNeutral: There is not relationship between premise and hypothesis\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Premise: {s1}\\n Hypothesis 2: {s2}\"}\n",
    "      ]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bf5a0f6-9409-4e14-9b4a-952a4b105e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation: Neutral\n",
      "\n",
      "Explanation: The premise states that a man is inspecting the uniform of a figure in some East Asian country. The hypothesis, on the other hand, suggests that the man is sleeping. There is no direct relationship between the two sentences, and they do not contradict or entail each other.\n"
     ]
    }
   ],
   "source": [
    "s1 = \"A man inspects the uniform of a figure in some East Asian country.\"\n",
    "s2 = \"The man is sleeping\"\n",
    "inference = nli(s1, s2)\n",
    "print(inference.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d19f75f-32c9-4db8-a6bc-3b1fe5b9f622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Neutral\n",
      "\n",
      "Explanation: The premise describes the image of two men smiling but does not provide any information about cats playing on the floor. The hypothesis adds additional information about the men laughing at the cats playing, which is not supported by the premise. However, there is no direct contradiction between the premise and the hypothesis. Hence, the relationship between the premise and hypothesis is considered neutral.\n"
     ]
    }
   ],
   "source": [
    "s1 = \"An older and younger man smiling.\t\"\n",
    "s2 = \"Two men are smiling and laughing at the cats playing on the floor.\"\n",
    "inference = nli(s1, s2)\n",
    "print(inference.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f0194fe6-9be2-49ee-b992-be24dff11843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral: There is no relationship between the premise and the hypothesis. The premise describes a specific scenario where a black race car starts up in front of a crowd of people, while the hypothesis describes a different scenario involving a man driving down a lonely road. The two sentences do not contradict each other, nor does one follow from the other.\n"
     ]
    }
   ],
   "source": [
    "s1 = \"A black race car starts up in front of a crowd of people.\"\n",
    "s2 = \"A man is driving down a lonely road.\"\n",
    "inference = nli(s1, s2)\n",
    "print(inference.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05961378-d36a-4612-a98f-b2dd1c8c8a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation: Entailment\n",
      "\n",
      "Explanation: The premise states that there is a soccer game with multiple males playing, which implies that there are men involved in a sport activity. Therefore, the hypothesis \"Some men are playing a sport\" follows logically from the fact stated in the premise.\n"
     ]
    }
   ],
   "source": [
    "s1 = \"A soccer game with multiple males playing.\"\n",
    "s2 = \"Some men are playing a sport.\"\n",
    "inference = nli(s1, s2)\n",
    "print(inference.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31660025",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Please submit a written report of what task you tried probing, how well did GPT3 do for that task and what were your key takeaways in this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66f992-cecb-41aa-8e95-d6e6f625c86c",
   "metadata": {},
   "source": [
    "I have explored the ChatGPT api and tried different things with it. I tried to implement the assignments using chatGPT to varying success.\n",
    "\n",
    "* #### Summarisation\n",
    "  The model worked great at summarizing text, I attempted to summarize the abstract of a paper using the model and it gave a satisfactory result.\n",
    "* #### POS Tagging\n",
    "  POS tagging also worked moderately well with pos tagging once given the tags we want to use, before that it had its own tags that I could not understand.\n",
    "* #### Irony detection\n",
    "  Irony detection also worked well, being able to detect the irony as well as lack of irony in the sentences provided\n",
    "* #### NLI\n",
    "  The model seems unable to perform NLI at all, always reporting neutral almost always. I tried to modify the prompt, however it was unable to correctly identify the correlation. I tried to have the model provide an explqanation and this allowed me to see that the two sentences must be almost exactly the same for the model to answer as entailement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
